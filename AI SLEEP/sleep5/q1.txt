import nltk
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize

nltk.download('punkt')
nltk.download('wordnet')

lemmatizer = WordNetLemmatizer()

text = "The quick brown foxes are jumping over the lazy dogs."

tokens = word_tokenize(text)
lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]

lemmatized_text = ' '.join(lemmatized_tokens)

print(lemmatized_text)
